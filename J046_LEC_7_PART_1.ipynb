{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61939935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75124917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/shreeshnadgouda/Downloads/resolved_queries.csv\")\n",
    "df1=pd.read_csv(\"/Users/shreeshnadgouda/Downloads/new_queries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f99f9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query_ID</th>\n",
       "      <th>Pre_Resolved_Query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Unable to connect to the internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Payment failed during checkout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>App crashes when opening settings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Forgot password and unable to reset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Unable to upload files to the server</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Query_ID                    Pre_Resolved_Query\n",
       "0         1     Unable to connect to the internet\n",
       "1         2        Payment failed during checkout\n",
       "2         3     App crashes when opening settings\n",
       "3         4   Forgot password and unable to reset\n",
       "4         5  Unable to upload files to the server"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad91613a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variation_Query</th>\n",
       "      <th>Matches_With_Query_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unabel to conect to the internet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can’t connect to internet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intenet not working</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payment failed while chekout</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Payment did not go through during chckout</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Payment issue at check out</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Application crashes when opening setings</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>App crash when going to settings</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Settings cause the app to chrash</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Forgot passwrd and cant reset</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Variation_Query  Matches_With_Query_ID\n",
       "0           Unabel to conect to the internet                      1\n",
       "1                  Can’t connect to internet                      1\n",
       "2                        Intenet not working                      1\n",
       "3               Payment failed while chekout                      2\n",
       "4  Payment did not go through during chckout                      2\n",
       "5                 Payment issue at check out                      2\n",
       "6   Application crashes when opening setings                      3\n",
       "7           App crash when going to settings                      3\n",
       "8           Settings cause the app to chrash                      3\n",
       "9              Forgot passwrd and cant reset                      4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672a64e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Obtaining dependency information for fuzzywuzzy from https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "Collecting python-Levenshtein\n",
      "  Obtaining dependency information for python-Levenshtein from https://files.pythonhosted.org/packages/72/8e/559c539e76bc0b1defec3da39a047fe151258efc9b215bf41db41e2c7922/python_Levenshtein-0.25.1-py3-none-any.whl.metadata\n",
      "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Levenshtein==0.25.1 (from python-Levenshtein)\n",
      "  Obtaining dependency information for Levenshtein==0.25.1 from https://files.pythonhosted.org/packages/58/4d/ebb238a39da4877493a41fc41763de3eb006fad13a531947f64f33622cfe/Levenshtein-0.25.1-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading Levenshtein-0.25.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-Levenshtein)\n",
      "  Obtaining dependency information for rapidfuzz<4.0.0,>=3.8.0 from https://files.pythonhosted.org/packages/3d/bc/38bd009fef815f2f2fa726019f0cc16ae600b7521acccb18a7afae63dbb6/rapidfuzz-3.9.7-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading rapidfuzz-3.9.7-cp310-cp310-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading Levenshtein-0.25.1-cp310-cp310-macosx_11_0_arm64.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.9.7-cp310-cp310-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8e9e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Obtaining dependency information for sentence-transformers from https://files.pythonhosted.org/packages/90/b4/52b8205f24172f2429cacf04bac324414f16b61d64e79c787c9ce2385586/sentence_transformers-3.1.0-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting transformers<5.0.0,>=4.38.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.38.0 from https://files.pythonhosted.org/packages/75/35/07c9879163b603f0e464b0f6e6e628a2340cfc7cdc5ca8e7d52d776710d4/transformers-4.44.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in ./miniforge3/lib/python3.10/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./miniforge3/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./miniforge3/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in ./miniforge3/lib/python3.10/site-packages (from sentence-transformers) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy in ./miniforge3/lib/python3.10/site-packages (from sentence-transformers) (1.12.0)\n",
      "Collecting huggingface-hub>=0.19.3 (from sentence-transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.19.3 from https://files.pythonhosted.org/packages/57/28/a0b0dd3cca63908045edc300360d6cd8758d4d86eee3fd2b08f00c5a41c4/huggingface_hub-0.24.7-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in ./miniforge3/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in ./miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniforge3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./miniforge3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in ./miniforge3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2)\n",
      "Requirement already satisfied: jinja2 in ./miniforge3/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniforge3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2023.12.25)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.38.0->sentence-transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.1 from https://files.pythonhosted.org/packages/2b/9e/9648d8dbb485c40a4a0212b7537626ae440b48156cc74601ca0b7a7615e0/safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.38.0->sentence-transformers)\n",
      "  Obtaining dependency information for tokenizers<0.20,>=0.19 from https://files.pythonhosted.org/packages/4c/12/9cb68762ff5fee1efd51aefe2f62cb225f26f060a68a3779e1060bbc7a59/tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./miniforge3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./miniforge3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniforge3/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniforge3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./miniforge3/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.1.0-py3-none-any.whl (249 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.7-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-macosx_11_0_arm64.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.24.7 safetensors-0.4.5 sentence-transformers-3.1.0 tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af7a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Obtaining dependency information for tf-keras from https://files.pythonhosted.org/packages/21/8b/75f7572ec0273ed8da50bc19defe08aaaafcc15fda3407db53f49acec814/tf_keras-2.17.0-py3-none-any.whl.metadata\n",
      "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow<2.18,>=2.17 (from tf-keras)\n",
      "  Obtaining dependency information for tensorflow<2.18,>=2.17 from https://files.pythonhosted.org/packages/1f/a1/7d2042050159619a190db874913a2bc70645f8ac677d442f9aab4d29153e/tensorflow-2.17.0-cp310-cp310-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading tensorflow-2.17.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.24.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.62.1)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Obtaining dependency information for tensorboard<2.18,>=2.17 from https://files.pythonhosted.org/packages/d4/41/dccba8c5f955bc35b6110ff78574e4e5c8226ad62f08e732096c3861309b/tensorboard-2.17.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow<2.18,>=2.17->tf-keras)\n",
      "  Obtaining dependency information for keras>=3.2.0 from https://files.pythonhosted.org/packages/a3/a4/101f0f3c0b057ce150af0e8493ab7fc10b98b066b7bd81ab01e96038a268/keras-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./miniforge3/lib/python3.10/site-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./miniforge3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in ./miniforge3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.6.0)\n",
      "Requirement already satisfied: namex in ./miniforge3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.7)\n",
      "Requirement already satisfied: optree in ./miniforge3/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniforge3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./miniforge3/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./miniforge3/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./miniforge3/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./miniforge3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./miniforge3/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./miniforge3/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./miniforge3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.17.0-cp310-cp310-macosx_12_0_arm64.whl (236.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.1/236.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard, keras, tensorflow, tf-keras\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.1.1\n",
      "    Uninstalling keras-3.1.1:\n",
      "      Successfully uninstalled keras-3.1.1\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-macos 2.16.1 requires tensorflow==2.16.1; platform_system == \"Darwin\" and platform_machine == \"arm64\", but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-3.5.0 tensorboard-2.17.1 tensorflow-2.17.0 tf-keras-2.17.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516dc7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Obtaining dependency information for ipywidgets from https://files.pythonhosted.org/packages/22/2d/9c0b76f2f9cc0ebede1b9371b6f317243028ed60b90705863d493bae622e/ipywidgets-8.1.5-py3-none-any.whl.metadata\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./miniforge3/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./miniforge3/lib/python3.10/site-packages (from ipywidgets) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./miniforge3/lib/python3.10/site-packages (from ipywidgets) (5.11.2)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Obtaining dependency information for widgetsnbextension~=4.0.12 from https://files.pythonhosted.org/packages/21/02/88b65cc394961a60c43c70517066b6b679738caf78506a5da7b88ffcb643/widgetsnbextension-4.0.13-py3-none-any.whl.metadata\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Obtaining dependency information for jupyterlab-widgets~=3.0.12 from https://files.pythonhosted.org/packages/a9/93/858e87edc634d628e5d752ba944c2833133a28fa87bb093e6832ced36a3e/jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: backcall in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pickleshare in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in ./miniforge3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./miniforge3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./miniforge3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./miniforge3/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./miniforge3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./miniforge3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in ./miniforge3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in ./miniforge3/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c43aae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreeshnadgouda/miniforge3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variation_Query</th>\n",
       "      <th>Matched_Query_ID_Ratio</th>\n",
       "      <th>Match_Score_Ratio</th>\n",
       "      <th>Matched_Query_ID_Partial_ratio</th>\n",
       "      <th>Match_Score_Partial_ratio</th>\n",
       "      <th>Matched_Query_ID_Token_sort_ratio</th>\n",
       "      <th>Match_Score_Token_sort_ratio</th>\n",
       "      <th>Matched_Query_ID_Token_set_ratio</th>\n",
       "      <th>Match_Score_Token_set_ratio</th>\n",
       "      <th>Matched_Query_ID_TFIDF</th>\n",
       "      <th>Match_Score_TFIDF</th>\n",
       "      <th>Matched_Query_ID_SBERT</th>\n",
       "      <th>Match_Score_SBERT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unabel to conect to the internet</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.839042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.303838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can’t connect to internet</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>0.836936</td>\n",
       "      <td>1</td>\n",
       "      <td>0.862849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intenet not working</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payment failed while chekout</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.629577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Payment did not go through during chckout</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.452279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Payment issue at check out</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.829703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Application crashes when opening setings</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>3</td>\n",
       "      <td>0.771926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>App crash when going to settings</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>0.722471</td>\n",
       "      <td>3</td>\n",
       "      <td>0.913933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Settings cause the app to chrash</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>0.508047</td>\n",
       "      <td>3</td>\n",
       "      <td>0.583386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Forgot passwrd and cant reset</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>0.782698</td>\n",
       "      <td>4</td>\n",
       "      <td>0.574612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Variation_Query  Matched_Query_ID_Ratio  \\\n",
       "0           Unabel to conect to the internet                       1   \n",
       "1                  Can’t connect to internet                       1   \n",
       "2                        Intenet not working                       1   \n",
       "3               Payment failed while chekout                       2   \n",
       "4  Payment did not go through during chckout                       2   \n",
       "5                 Payment issue at check out                       2   \n",
       "6   Application crashes when opening setings                       3   \n",
       "7           App crash when going to settings                       3   \n",
       "8           Settings cause the app to chrash                       3   \n",
       "9              Forgot passwrd and cant reset                       4   \n",
       "\n",
       "   Match_Score_Ratio  Matched_Query_ID_Partial_ratio  \\\n",
       "0                 95                               1   \n",
       "1                 77                               1   \n",
       "2                 42                               1   \n",
       "3                 83                               2   \n",
       "4                 70                               2   \n",
       "5                 71                               2   \n",
       "6                 88                               3   \n",
       "7                 86                               3   \n",
       "8                 40                               3   \n",
       "9                 84                               4   \n",
       "\n",
       "   Match_Score_Partial_ratio  Matched_Query_ID_Token_sort_ratio  \\\n",
       "0                         94                                  1   \n",
       "1                         83                                  1   \n",
       "2                         53                                  1   \n",
       "3                         79                                  2   \n",
       "4                         61                                  2   \n",
       "5                         62                                  2   \n",
       "6                         89                                  3   \n",
       "7                         84                                  3   \n",
       "8                         41                                  3   \n",
       "9                         76                                  4   \n",
       "\n",
       "   Match_Score_Token_sort_ratio  Matched_Query_ID_Token_set_ratio  \\\n",
       "0                            95                                 1   \n",
       "1                            67                                 1   \n",
       "2                            46                                 1   \n",
       "3                            76                                 2   \n",
       "4                            65                                 2   \n",
       "5                            57                                 2   \n",
       "6                            88                                 3   \n",
       "7                            86                                 3   \n",
       "8                            65                                 3   \n",
       "9                            75                                 4   \n",
       "\n",
       "   Match_Score_Token_set_ratio  Matched_Query_ID_TFIDF  Match_Score_TFIDF  \\\n",
       "0                           95                       1           0.839042   \n",
       "1                           88                       1           0.836936   \n",
       "2                           49                       1           0.000000   \n",
       "3                           83                       2           0.707107   \n",
       "4                           70                       2           0.707107   \n",
       "5                           57                       2           0.500000   \n",
       "6                           88                       3           0.774597   \n",
       "7                           86                       3           0.722471   \n",
       "8                           65                       3           0.508047   \n",
       "9                           75                       4           0.782698   \n",
       "\n",
       "   Matched_Query_ID_SBERT  Match_Score_SBERT  \n",
       "0                       1           0.303838  \n",
       "1                       1           0.862849  \n",
       "2                       1           0.145931  \n",
       "3                       2           0.629577  \n",
       "4                       2           0.452279  \n",
       "5                       2           0.829703  \n",
       "6                       3           0.771926  \n",
       "7                       3           0.913933  \n",
       "8                       3           0.583386  \n",
       "9                       4           0.574612  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Assuming df is the resolved_queries and df1 is the new_queries\n",
    "resolved_queries = df\n",
    "new_queries = df1\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "resolved_queries['Processed_Query'] = resolved_queries['Pre_Resolved_Query'].apply(preprocess_text)\n",
    "new_queries['Processed_Variation_Query'] = new_queries['Variation_Query'].apply(preprocess_text)\n",
    "\n",
    "# Optimized fuzzy matching function (using NumPy for vectorized operations)\n",
    "def fuzzy_match_batch(queries, resolved_queries, method='ratio'):\n",
    "    query_list = resolved_queries['Processed_Query'].values\n",
    "    match_ids = []\n",
    "    match_scores = []\n",
    "    \n",
    "    for query in queries:\n",
    "        if method == 'ratio':\n",
    "            scores = np.array([fuzz.ratio(query, resolved) for resolved in query_list])\n",
    "        elif method == 'partial_ratio':\n",
    "            scores = np.array([fuzz.partial_ratio(query, resolved) for resolved in query_list])\n",
    "        elif method == 'token_sort_ratio':\n",
    "            scores = np.array([fuzz.token_sort_ratio(query, resolved) for resolved in query_list])\n",
    "        elif method == 'token_set_ratio':\n",
    "            scores = np.array([fuzz.token_set_ratio(query, resolved) for resolved in query_list])\n",
    "        \n",
    "        best_match_idx = scores.argmax()\n",
    "        match_ids.append(resolved_queries.iloc[best_match_idx]['Query_ID'])\n",
    "        match_scores.append(scores[best_match_idx])\n",
    "    \n",
    "    return match_ids, match_scores\n",
    "\n",
    "# Apply fuzzy matching using different methods\n",
    "methods = ['ratio', 'partial_ratio', 'token_sort_ratio', 'token_set_ratio']\n",
    "fuzzy_results = {}\n",
    "\n",
    "for method in methods:\n",
    "    match_ids, match_scores = fuzzy_match_batch(new_queries['Processed_Variation_Query'], resolved_queries, method)\n",
    "    fuzzy_results[f'Matched_Query_ID_{method.capitalize()}'] = match_ids\n",
    "    fuzzy_results[f'Match_Score_{method.capitalize()}'] = match_scores\n",
    "\n",
    "# Fuzzy matching results\n",
    "fuzzy_df = pd.DataFrame(fuzzy_results)\n",
    "fuzzy_df.insert(0, 'Variation_Query', new_queries['Variation_Query'])\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_resolved = vectorizer.fit_transform(resolved_queries['Processed_Query'])\n",
    "tfidf_new = vectorizer.transform(new_queries['Processed_Variation_Query'])\n",
    "\n",
    "# Cosine similarity with TF-IDF\n",
    "cosine_similarities = cosine_similarity(tfidf_new, tfidf_resolved)\n",
    "best_match_indices = cosine_similarities.argmax(axis=1)\n",
    "best_match_scores = cosine_similarities.max(axis=1)\n",
    "matched_query_ids = resolved_queries.iloc[best_match_indices]['Query_ID'].values\n",
    "\n",
    "# TF-IDF results\n",
    "tfidf_results = pd.DataFrame({\n",
    "    'Variation_Query': new_queries['Variation_Query'],\n",
    "    'Matched_Query_ID_TFIDF': matched_query_ids,\n",
    "    'Match_Score_TFIDF': best_match_scores\n",
    "})\n",
    "\n",
    "# Use pre-trained model for semantic similarity (Sentence-BERT)\n",
    "# Load Sentence-BERT model for better sentence embeddings\n",
    "sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Encode both resolved and new queries\n",
    "sbert_resolved_embeddings = sbert_model.encode(resolved_queries['Processed_Query'].values)\n",
    "sbert_new_embeddings = sbert_model.encode(new_queries['Processed_Variation_Query'].values)\n",
    "\n",
    "# Compute cosine similarity for Sentence-BERT embeddings\n",
    "sbert_similarities = cosine_similarity(sbert_new_embeddings, sbert_resolved_embeddings)\n",
    "best_sbert_match_indices = sbert_similarities.argmax(axis=1)\n",
    "best_sbert_match_scores = sbert_similarities.max(axis=1)\n",
    "matched_sbert_query_ids = resolved_queries.iloc[best_sbert_match_indices]['Query_ID'].values\n",
    "\n",
    "# Sentence-BERT results\n",
    "sbert_results = pd.DataFrame({\n",
    "    'Variation_Query': new_queries['Variation_Query'],\n",
    "    'Matched_Query_ID_SBERT': matched_sbert_query_ids,\n",
    "    'Match_Score_SBERT': best_sbert_match_scores\n",
    "})\n",
    "\n",
    "# Combine all results for comparison\n",
    "final_results = pd.concat([fuzzy_df, tfidf_results[['Matched_Query_ID_TFIDF', 'Match_Score_TFIDF']], \n",
    "                           sbert_results[['Matched_Query_ID_SBERT', 'Match_Score_SBERT']]], axis=1)\n",
    "\n",
    "# Display the final results\n",
    "final_results.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1ec04",
   "metadata": {},
   "source": [
    "### Output Inference:\n",
    "\n",
    "The output contains results from several text-matching methods (Fuzzy Matching, TF-IDF, and Sentence-BERT) applied to a set of `Variation_Query` strings compared to a set of `Resolved_Queries`. Each method attempts to find the closest match between the `Variation_Query` and the `Resolved_Queries`, along with a similarity score for each match. Here is the detailed inference of the output:\n",
    "\n",
    "#### **Row 0:**\n",
    "- **Variation Query**: \"Unabel to conect to the internet\" (misspelled)\n",
    "- **Best Match**: `Query_ID 1`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching (Ratio, Partial, Token Sort, Token Set): High scores (~95) indicate a strong match despite the typo.\n",
    "  - TF-IDF: 0.839, which shows a good vectorized match.\n",
    "  - SBERT: 0.303, much lower because SBERT is sensitive to spelling errors.\n",
    "  \n",
    "**Conclusion**: Fuzzy Matching performs well on this misspelled query, but SBERT struggles due to the misspelling.\n",
    "\n",
    "#### **Row 1:**\n",
    "- **Variation Query**: \"Can’t connect to internet\"\n",
    "- **Best Match**: `Query_ID 1`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Scores range from 67 to 88, showing decent performance.\n",
    "  - TF-IDF: 0.837, good match with vectorization.\n",
    "  - SBERT: 0.863, a high score showing SBERT understood the semantic similarity well.\n",
    "\n",
    "**Conclusion**: All methods, including SBERT, perform well here because the query is clear and well-formed.\n",
    "\n",
    "#### **Row 2:**\n",
    "- **Variation Query**: \"Intenet not working\" (misspelled \"internet\")\n",
    "- **Best Match**: `Query_ID 1`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Lower scores (~42–53) due to the typo.\n",
    "  - TF-IDF: 0, showing it did not find a good match.\n",
    "  - SBERT: 0.146, indicating a poor semantic match.\n",
    "\n",
    "**Conclusion**: Both TF-IDF and SBERT perform poorly due to the misspelling, while Fuzzy Matching handles it better.\n",
    "\n",
    "#### **Row 3:**\n",
    "- **Variation Query**: \"Payment failed while chekout\" (misspelled \"checkout\")\n",
    "- **Best Match**: `Query_ID 2`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Decent scores (76–83), showing it found a close match despite the typo.\n",
    "  - TF-IDF: 0.707, showing a good match in vector space.\n",
    "  - SBERT: 0.630, indicating decent semantic similarity.\n",
    "\n",
    "**Conclusion**: All methods perform reasonably well, but Fuzzy Matching and SBERT slightly outperform TF-IDF.\n",
    "\n",
    "#### **Row 4:**\n",
    "- **Variation Query**: \"Payment did not go through during chckout\" (misspelled \"checkout\")\n",
    "- **Best Match**: `Query_ID 2`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Scores in the 60–70 range, reflecting the impact of the typo.\n",
    "  - TF-IDF: 0.707, good match in vector space.\n",
    "  - SBERT: 0.452, lower score due to the typo affecting semantic matching.\n",
    "\n",
    "**Conclusion**: Fuzzy Matching handles the typo better than SBERT, while TF-IDF performs similarly to Row 3.\n",
    "\n",
    "#### **Row 5:**\n",
    "- **Variation Query**: \"Payment issue at check out\"\n",
    "- **Best Match**: `Query_ID 2`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Lower scores (57–71) than previous payment queries.\n",
    "  - TF-IDF: 0.500, moderate performance.\n",
    "  - SBERT: 0.830, very strong semantic match.\n",
    "\n",
    "**Conclusion**: SBERT outperforms here due to its strong semantic understanding, while Fuzzy Matching and TF-IDF are moderate.\n",
    "\n",
    "#### **Row 6:**\n",
    "- **Variation Query**: \"Application crashes when opening setings\" (misspelled \"settings\")\n",
    "- **Best Match**: `Query_ID 3`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Scores around 88, good match despite the typo.\n",
    "  - TF-IDF: 0.775, strong match.\n",
    "  - SBERT: 0.772, strong semantic understanding.\n",
    "\n",
    "**Conclusion**: All methods perform well, with SBERT showing good semantic understanding despite the typo.\n",
    "\n",
    "#### **Row 7:**\n",
    "- **Variation Query**: \"App crash when going to settings\"\n",
    "- **Best Match**: `Query_ID 3`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Scores in the high 80s, indicating strong performance.\n",
    "  - TF-IDF: 0.722, good match.\n",
    "  - SBERT: 0.914, the highest score indicating excellent semantic matching.\n",
    "\n",
    "**Conclusion**: SBERT performs best, showcasing its ability to understand the intent of the query.\n",
    "\n",
    "#### **Row 8:**\n",
    "- **Variation Query**: \"Settings cause the app to chrash\" (misspelled \"crash\")\n",
    "- **Best Match**: `Query_ID 3`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Scores are moderate (~40–65) due to the typo.\n",
    "  - TF-IDF: 0.508, indicating a weaker match.\n",
    "  - SBERT: 0.583, moderate semantic understanding.\n",
    "\n",
    "**Conclusion**: All methods struggle with the typo, but SBERT still gives a reasonably good score compared to TF-IDF and Fuzzy Matching.\n",
    "\n",
    "#### **Row 9:**\n",
    "- **Variation Query**: \"Forgot passwrd and cant reset\" (misspelled \"password\")\n",
    "- **Best Match**: `Query_ID 4`\n",
    "- **Scores**:\n",
    "  - Fuzzy Matching: Scores in the 70s, showing decent performance despite the typo.\n",
    "  - TF-IDF: 0.783, strong match.\n",
    "  - SBERT: 0.575, lower due to the typo.\n",
    "\n",
    "**Conclusion**: Fuzzy Matching and TF-IDF handle the typo better, but SBERT's semantic understanding is affected by the misspelling.\n",
    "\n",
    "---\n",
    "\n",
    "### **General Insights**:\n",
    "- **Fuzzy Matching** is effective at handling typos and minor misspellings but may struggle with more complex semantic differences.\n",
    "- **TF-IDF** performs well on well-formed queries but struggles with misspellings or varying word choices.\n",
    "- **SBERT** shines when queries are semantically similar, but its performance can drop significantly with spelling errors or typos.\n",
    "\n",
    "For optimal matching performance, combining the strengths of all three methods could yield the best results, especially in handling both typographical errors and semantic variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1a80a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-env)",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
